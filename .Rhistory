colnames(missing_df)<-c("variable", "missingcount", "missingproportion")
missing_df$variable<-colnames(df_missing_removed)
for(i in 1:ncol(df_missing_removed)){
missing_df[i,2]<-sum(is.na(df_missing_removed[,i])==T)
missing_df[i,3]<-sum(is.na(df_missing_removed[,i])==T) / nrow(df_missing_removed)
}
# Remove last bits of high missingness in dataframe
colnames(df_missing_removed)
df_missing_removed<-dplyr::select(df_missing_removed, -B_Transgender, -S_LangChoice)
finalfit::missing_plot(df_missing_removed)
# Remove NA cases from final dataframe (clean_df)
clean_df<-na.omit(df_missing_removed)
finalfit::missing_plot(clean_df)
# Prepare data for investigating depression
clean_df<-clean_df[,-c(2)]
X<-clean_df[,-c(120)]
y<-clean_df[,c(120)]
colnames(X)
library(reticulate)
use_condaenv("mlbase", required=T)
X_py<-r_to_py(X)
y_py<-r_to_py(y)
colnames(clean_df)
reticulate::repl_python()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import KFold, cross_val_predict
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.metrics import r2_score
from sklearn.pipeline import Pipeline
# Read Data
X = r.X_py
y = r.y_py
# The KFold object in SciKit Learn tells the cross validation object (see below) how to split up the data:
# Initiate KFold Object
kf = KFold(shuffle=True, random_state=72018, n_splits=4)
kf.split(X) # is a generator object
X.describe()
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import GridSearchCV
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler
from sklearn.model_selection import KFold, cross_val_predict
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.metrics import r2_score
from sklearn.pipeline import Pipeline
# Read Data
X = r.X_py
y = r.y_py
# Same estimator as before
estimator = Pipeline([("scaler", MinMaxScaler()),
("lasso_regression", Lasso())])
params = {
'lasso_regression__alpha': np.geomspace(4, 20, 30)
}
grid = GridSearchCV(estimator, params, cv=kf)
grid.fit(X, y)
grid.best_score_, grid.best_params_
y_predict = grid.predict(X)
r2_score(y, y_predict)
grid.best_estimator_.named_steps['ridge_regression'].coef_
grid.best_estimator_.named_steps['lasso_regression'].coef_
np.geomspace(1, 4, 20)
# Same estimator as before
estimator = Pipeline([("scaler", MinMaxScaler()),
("lasso_regression", Lasso())])
params = {
'lasso_regression__alpha': np.geomspace(1, 4, 20)
}
grid = GridSearchCV(estimator, params, cv=kf)
grid.fit(X, y)
grid.best_score_, grid.best_params_
y_predict = grid.predict(X)
# This includes both in-sample and out-of-sample
r2_score(y, y_predict)
# Same estimator as before
estimator = Pipeline([("scaler", StandardScaler()),
("ridge_regression", Lasso())])
params = {
'ridge_regression__alpha': np.geomspace(4, 20, 30)
}
grid = GridSearchCV(estimator, params, cv=kf)
grid.fit(X, y)
grid.best_score_, grid.best_params_
y_predict = grid.predict(X)
# This includes both in-sample and out-of-sample
r2_score(y, y_predict)
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import GridSearchCV
# Same estimator as before
estimator = Pipeline([("scaler", StandardScaler()),
("ridge_regression", Ridge())])
params = {
'ridge_regression__alpha': np.geomspace(4, 20, 30)
}
grid = GridSearchCV(estimator, params, cv=kf)
grid.fit(X, y)
grid.best_score_, grid.best_params_
y_predict = grid.predict(X)
# This includes both in-sample and out-of-sample
r2_score(y, y_predict)
grid.best_estimator_.named_steps['ridge_regression'].coef_
GridResults = pd.DataFrame(grid.cv_results_)
GridResults.rank_test_score.sort_values()
print(GridResults.loc[54])
GridResults = pd.DataFrame(grid.cv_results_)
GridResults
GridResults.rank_test_score.sort_values()
GridResults = pd.DataFrame(grid.cv_results_)
GridResults.rank_test_score.sort_values()
print(GridResults.loc[29])
print(GridResults.loc[30])
print(GridResults.loc[28])
print(GridResults.loc[29])
print(GridResults.params.loc[29])
grid.get_params
grid.best_estimator_
grid.best_score_, grid.best_params_
grid.best_index_
GridResults
print(GridResults.params.loc[29])
grid
r2_score(y, y_predict)
grid.best_estimator_.named_steps['ridge_regression'].coef_
len(grid.best_estimator_.named_steps['ridge_regression'].coef_)
X.shape
Ridge_Coefs = grid.best_estimator_.named_steps['ridge_regression'].coef_
Ridge_Coefs = grid.best_estimator_.named_steps['ridge_regression'].coef_
Varnames = X.columns
Ridge_Coefs = grid.best_estimator_.named_steps['ridge_regression'].coef_
Varnames = X.columns
# Zip the two lists together
zipped_list = list(zip(Varnames, Ridge_Coefs))
# Convert the zipped list to a DataFrame
df = pd.DataFrame(zipped_list, columns=['Variable', 'Coefficient'])
# Print the DataFrame
print(df)
df.to_csv('Ridge_Coefficients.csv')
quit
y<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
S_MHI_diag_5,
Diener5,
B_Sex_Pr_2,
Race_White,
S_MHI_diag_8,
S_MHI_diag_36)
y<-clean_df$UA_SUICIDE_Attempted
X_py<-r_to_py(X)
y_py<-r_to_py(y)
fit<-glm(UA_SUICIDE_Attempted~., family = binomial(link = "logit"), data = New_df)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
S_MHI_diag_5,
Diener5,
B_Sex_Pr_2,
Race_White,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
fit<-glm(UA_SUICIDE_Attempted~., family = binomial(link = "logit"), data = New_df)
UA_SUICIDE_Attempted
New_df$UA_SUICIDE_Attempted
fit<-lm(UA_SUICIDE_Attempted~., data = New_df)
summary(fit)
for(i in 1:13){
New_df[,i]<-mean(New_df[,i])-New_df[,i]
}
New_df$UA_SUICIDE_Attempted
fit<-lm(UA_SUICIDE_Attempted~., data = New_df)
summary(fit)
hist(New_df$S_MHI_diag_5
hist(New_df$S_MHI_diag_5
hist(New_df$S_MHI_diag_5)
table(New_df$S_MHI_diag_5)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
Race_White,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
for(i in 1:13){
New_df[,i]<-mean(New_df[,i])-New_df[,i]
}
New_df$UA_SUICIDE_Attempted
table(New_df$S_MHI_diag_5)
fit<-lm(UA_SUICIDE_Attempted~., data = New_df)
summary(fit)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
for(i in 1:13){
New_df[,i]<-mean(New_df[,i])-New_df[,i]
}
New_df$UA_SUICIDE_Attempted
table(New_df$S_MHI_diag_5)
fit<-lm(UA_SUICIDE_Attempted~., data = New_df)
summary(fit)
table(New_df$S_MHI_diag_8)
table(New_df$S_MHI_diag_36)
df<-read.csv("Baseline_Calendly_Hubspot Data Combined [no emails].csv", header=T, sep=",", encoding='utf-8-rom')
# Examine patterns of missing data
library(finalfit)
finalfit::missing_plot(df)
# View Columns in Dataset
colnames(df)
# Turn NA for Graduate Student (0 vs. 1) into 0's
df$GraduateStudent<-ifelse(is.na(df$GraduateStudent)==T, 0, df$GraduateStudent)
# Create a new dataframe to display missing data for each variable
missing_df<-as.data.frame(matrix(data=NA, ncol = 3, nrow = ncol(df)))
colnames(missing_df)<-c("variable", "missingcount", "missingproportion")
missing_df$variable<-colnames(df)
for(i in 1:ncol(df)){
missing_df[i,2]<-sum(is.na(df[,i])==T)
missing_df[i,3]<-sum(is.na(df[,i])==T) / nrow(df)
}
# Compile list of variables that are missing 100% of rows...
missing_all<-missing_df[missing_df$missingproportion==1,]
allmissing_list<-missing_all$variable
# Print the list of variables that are missing at 100%
allmissing_list
# Make new dataframe that removes all variables that have 100% missingness
df_missing_removed<-dplyr::select(df, -allmissing_list)
colnames(df_missing_removed)
# Removing more columns that cannot be used (i.e., TEXT responses to some 'other' items)
df_missing_removed<- df_missing_removed[,-c(1:8, 10:20, 23:26, 15,16,26,36,52,53,56,58,68:69,71:80,90:95,115,121:287,324:334,349:410,420:424)]
finalfit::missing_plot(df_missing_removed)
colnames(df_missing_removed)
# Find column numbers for variables that need to be converted to "numeric"
# Also turns NAs in these columns into 0's
numcols<-c(1,3:28,32:39, 42:55, 68:70, 73:109)
for(col in numcols){
df_missing_removed[,col]<-as.numeric(unlist(df_missing_removed[,col]))
df_missing_removed[,col]<-ifelse(is.na(df_missing_removed[,col])==T, 0, df_missing_removed[,col])
}
finalfit::missing_plot(df_missing_removed)
# Create a new dataframe to display missing data for each variable
missing_df<-as.data.frame(matrix(data=NA, ncol = 3, nrow = ncol(df_missing_removed)))
colnames(missing_df)<-c("variable", "missingcount", "missingproportion")
missing_df$variable<-colnames(df_missing_removed)
for(i in 1:ncol(df_missing_removed)){
missing_df[i,2]<-sum(is.na(df_missing_removed[,i])==T)
missing_df[i,3]<-sum(is.na(df_missing_removed[,i])==T) / nrow(df_missing_removed)
}
# Remove last bits of high missingness in dataframe
colnames(df_missing_removed)
df_missing_removed<-dplyr::select(df_missing_removed, -B_Transgender, -S_LangChoice)
finalfit::missing_plot(df_missing_removed)
# Remove NA cases from final dataframe (clean_df)
clean_df<-na.omit(df_missing_removed)
finalfit::missing_plot(clean_df)
# Prepare data for investigating depression
clean_df<-clean_df[,-c(2)]
X<-clean_df[,-c(120)]
y<-clean_df[,c(120)]
colnames(X)
library(reticulate)
use_condaenv("mlbase", required=T)
X_py<-r_to_py(X)
y_py<-r_to_py(y)
colnames(clean_df)
reticulate::repl_python()
# Grid Search CV
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler
from sklearn.model_selection import KFold, cross_val_predict
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.metrics import r2_score
from sklearn.pipeline import Pipeline
# Read Data
X = r.X_py
y = r.y_py
# Initiate KFold Object
kf = KFold(shuffle=True, random_state=72018, n_splits=4)
kf.split(X) # is a generator object
X.describe()
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import GridSearchCV
# Same estimator as before
estimator = Pipeline([("scaler", StandardScaler()),
("ridge_regression", Ridge())])
params = {
'ridge_regression__alpha': np.geomspace(4, 20, 30)
}
grid = GridSearchCV(estimator, params, cv=kf)
grid.fit(X, y)
grid.best_score_, grid.best_params_
grid.best_estimator_.
y_predict = grid.predict(X)
# This includes both in-sample and out-of-sample
r2_score(y, y_predict)
Ridge_Coefs = grid.best_estimator_.named_steps['ridge_regression'].coef_
Varnames = X.columns
# Zip the two lists together
zipped_list = list(zip(Varnames, Ridge_Coefs))
# Convert the zipped list to a DataFrame
df = pd.DataFrame(zipped_list, columns=['Variable', 'Coefficient'])
# Print the DataFrame
print(df)
print(GridResults.loc[29])
print(GridResults.params.loc[29])
df.to_csv('Ridge_Coefficients.csv')
GridResults = pd.DataFrame(grid.cv_results_)
GridResults.rank_test_score.sort_values()
print(GridResults.loc[29])
print(GridResults.params.loc[29])
grid.best_estimator_
quit
set.seed(123)  # For reproducibility
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
set.seed(123)  # For reproducibility
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
library(caret)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
set.seed(123)  # For reproducibility
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
split <- caret::sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
library(caTools)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
set.seed(123)  # For reproducibility
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
clean_df<-na.omit(clean_df)
library(caret)
library(caTools)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
set.seed(123)  # For reproducibility
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
New_df<-na.omit(New_df)
for(i in 1:13){
New_df[,i]<-mean(New_df[,i])-New_df[,i]
}
ncol(New_df)
library(caret)
library(caTools)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
set.seed(123)  # For reproducibility
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
New_df<-na.omit(New_df)
for(i in 1:11){
New_df[,i]<-mean(New_df[,i])-New_df[,i]
}
New_df$UA_SUICIDE_Attempted
# Create training and testing sets
training <- subset(New_df, split == TRUE)
testing <- subset(New_df, split == FALSE)
fit<-lm(UA_SUICIDE_Attempted~., data = New_df)
fit<-lm(UA_SUICIDE_Attempted~., data = training)
summary(fit)
pred<-predict(fit, testing)
error<- pred - testing$UA_SUICIDE_Considered
MAE<- mean(abs(error))
print(round(MAE, 3))
SE <- sd(error)
print(round(SE, 3))
hist(error)
pred
pred<-round(predict(fit, testing),0)
error<- pred - testing$UA_SUICIDE_Considered
MAE<- mean(abs(error))
print(round(MAE, 3))
SE <- sd(error)
print(round(SE, 3))
hist(error)
mean(testing$UA_SUICIDE_Considered)
testing$UA_SUICIDE_Considered
library(caret)
library(caTools)
New_df<-dplyr::select(clean_df, UA_SUICIDE_Considered,
PHQ9_2,
Diener4,
Race_Black,
B_Sex_Pr_1,
S_MHI_diag_11,
Diener3,
Diener5,
B_Sex_Pr_2,
S_MHI_diag_8,
S_MHI_diag_36,
UA_SUICIDE_Attempted)
set.seed(123)  # For reproducibility
split <- sample.split(New_df$UA_SUICIDE_Attempted, SplitRatio = 0.7)  # 70% training data
New_df<-na.omit(New_df)
for(i in 1:11){
New_df[,i]<-mean(New_df[,i])-New_df[,i]
}
New_df$UA_SUICIDE_Attempted
# Create training and testing sets
training <- subset(New_df, split == TRUE)
testing <- subset(New_df, split == FALSE)
fit<-lm(UA_SUICIDE_Attempted~., data = training)
summary(fit)
pred<-round(predict(fit, testing),0)
error<- pred - testing$UA_SUICIDE_Attempted
MAE<- mean(abs(error))
print(round(MAE, 3))
SE <- sd(error)
print(round(SE, 3))
hist(error)
mean(testing$UA_SUICIDE_Attempted)
fit<-lm(UA_SUICIDE_Attempted~., data = training)
summary(fit)
# Generate predictions
pred <- round(predict(fit, testing), 0)
# Calculate error
error <- pred - testing$UA_SUICIDE_Attempted
# Calculate MAE
MAE <- mean(abs(error))
print(paste("Mean Absolute Error (MAE):", round(MAE, 3)))
# Calculate Standard Error
SE <- sd(error)
print(paste("Standard Error (SE):", round(SE, 3)))
# Plot histogram of errors
hist(error, main="Histogram of Prediction Errors", xlab="Error")
# Calculate mean of the actual values
mean_actual <- mean(testing$UA_SUICIDE_Attempted)
print(paste("Mean of Actual Values:", round(mean_actual, 3)))
# Calculate Total Sum of Squares (TSS)
TSS <- sum((testing$UA_SUICIDE_Attempted - mean_actual)^2)
# Calculate Residual Sum of Squares (RSS)
RSS <- sum(error^2)
# Calculate R-squared (R2)
R2 <- 1 - (RSS/TSS)
print(paste("R-squared (R2):", round(R2, 3)))
summary(fit)
